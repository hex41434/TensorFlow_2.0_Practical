# -*- coding: utf-8 -*-
"""Bonus 2: Transfer Learning for Image Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z-mBjrBUB6z-E-dvaJc-XFoR96mcSXhc

# STEP #0: PROBLEM STATEMENT

- Transfer learning is a machine learning technique in which intelligence (i.e.: weights) from a base artificial neural network is being transferred to a new network as a starting point to perform a specific task. 
- In this project, we will apply Transfer learning to repurpose trained weights from ResNet 50, which is a famous deep network, to perform classification tasks on a new datasets. 
- A pre-trained ResNet50 model that has been trained on ImageNet will be repurposed and used to classify new images of cats and dogs
- The new model will consist of two part: 
    - (1) "base" pre-trained network  
    - (2) "new dense network classifier"
- Citations: Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg and Li Fei-Fei. (* = equal contribution) ImageNet Large Scale Visual Recognition Challenge. arXiv:1409.0575, 2014.
- Paper: https://arxiv.org/abs/1409.0575
- Data Source: https://www.kaggle.com/tongpython/cat-and-dog

# STEP #1: IMPORT LIBRARIES
"""

!pip install tensorflow-gpu==2.0.0.alpha0

import tensorflow as tf

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import random

tf.__version__

"""# STEP #2: IMPORT MODEL WITH PRE-TRAINED WEIGHTS"""

model = tf.keras.applications.ResNet50(weights = 'imagenet')

"""# STEP #3: EVALUATE THE PRE-TRAINED MODEL (JUST TO BE SURE :)!)

- Check this out: http://www.image-net.org/synset?wnid=n02835271
- Search for Bicycle
- https://lear.inrialpes.fr/people/gordo/ImageNetResults/sift1000_accuracy_withPrior/results_sift_0253.htm
"""

from google.colab import drive
drive.mount('/content/drive')

# Sample_Image= tf.keras.preprocessing.image.load_img(r'/content/drive/My Drive/Colab Notebooks/Transfer Learning Data/African_Elephant.jpg', target_size = (224, 224))

Sample_Image= tf.keras.preprocessing.image.load_img(r'/content/drive/My Drive/Colab Notebooks/Transfer Learning Data/bicycle.png', target_size = (224, 224))

Sample_Image = tf.keras.preprocessing.image.img_to_array(Sample_Image)

np.shape(Sample_Image)

plt.imshow(Sample_Image)

Sample_Image = np.expand_dims(Sample_Image, axis = 0)
np.shape(Sample_Image)

Sample_Image.max()

Sample_Image.min()

Sample_Image = tf.keras.applications.resnet50.preprocess_input(Sample_Image)

Sample_Image.max()

Sample_Image.min()

predictions = model.predict(Sample_Image)

print('predictions:', tf.keras.applications.resnet50.decode_predictions(predictions, top = 5)[0])

"""# STEP #4: APPLY TRANSFER LEARNING AND RETRAIN THE MODEL"""

base_model = tf.keras.applications.ResNet50(weights = 'imagenet', include_top = False)

print(base_model.summary())

for i, layer in enumerate(base_model.layers):
    print(i, layer.name)

x = base_model.output
x = tf.keras.layers.GlobalAveragePooling2D()(x)

x = tf.keras.layers.Dense(1024, activation = 'relu')(x)
x = tf.keras.layers.Dense(1024, activation = 'relu')(x)
x = tf.keras.layers.Dense(1024, activation = 'relu')(x)
x = tf.keras.layers.Dense(512, activation = 'relu')(x)
preds = tf.keras.layers.Dense(2, activation = 'softmax')(x)

model = tf.keras.models.Model(inputs = base_model.input, outputs = preds)

print(model.summary())

for i, layer in enumerate(model.layers):
    print(i, layer.name)

for layer in model.layers[:175]:
    layer.trainable = False

for layer in model.layers[175:]:
    layer.trainable = True

train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function= tf.keras.applications.resnet50.preprocess_input)

train_generator = train_datagen.flow_from_directory('/content/drive/My Drive/Colab Notebooks/Transfer Learning Data/train/', 
                                                   target_size = (224, 224),
                                                   color_mode = 'rgb',
                                                   batch_size = 32,
                                                   class_mode = 'categorical',
                                                   shuffle = True)

model.compile(optimizer = 'Adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])

history = model.fit_generator(generator = train_generator, steps_per_epoch=train_generator.n//train_generator.batch_size, epochs = 5)

"""# STEP #5: EVALUATE THE MODEL"""

acc = history.history['accuracy']
loss = history.history['loss']

plt.figure()
plt.plot(acc, label='Training Accuracy')
plt.ylabel('Accuracy')
plt.title('Training Accuracy')

plt.figure()

plt.plot(loss, label='Training Loss')
plt.ylabel('Loss')
plt.title('Training Loss')
plt.xlabel('epoch')
plt.show()

Sample_Image= tf.keras.preprocessing.image.load_img(r'/content/drive/My Drive/Colab Notebooks/Transfer Learning Data/cat.282.jpg', target_size = (224, 224))

# Sample_Image= tf.keras.preprocessing.image.load_img(r'/content/drive/My Drive/Colab Notebooks/Transfer Learning Data/dog.309.jpg', target_size = (224, 224))

plt.imshow(Sample_Image)

Sample_Image = tf.keras.preprocessing.image.img_to_array(Sample_Image)
np.shape(Sample_Image)

Sample_Image = np.expand_dims(Sample_Image, axis = 0)

Sample_Image = tf.keras.applications.resnet50.preprocess_input(Sample_Image)
predictions = model.predict(Sample_Image)
print('Predictions:', predictions)

"""# GREAT JOB!"""
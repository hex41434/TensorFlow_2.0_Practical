{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_1 Temp Conversion.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cailyn-craven/TensorFlow_2.0_Practical/blob/master/Project_1_Temp_Conversion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOCdZmoVtk3e",
        "colab_type": "code",
        "outputId": "c35ef569-6848-41a5-c909-f587b2028521",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        }
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0.alpha0\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0.alpha0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/66/32cffad095253219d53f6b6c2a436637bbe45ac4e7be0244557210dc3918/tensorflow_gpu-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl (332.1MB)\n",
            "\u001b[K     |████████████████████████████████| 332.1MB 48kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.8.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.9.0)\n",
            "Collecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 49.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.12.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.17.5)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 61.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.33.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.1.8)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.0.8)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (3.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0.alpha0) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0.alpha0) (0.16.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0.alpha0) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0.alpha0) (42.0.2)\n",
            "Installing collected packages: tb-nightly, tf-estimator-nightly, tensorflow-gpu\n",
            "Successfully installed tb-nightly-1.14.0a20190301 tensorflow-gpu-2.0.0a0 tf-estimator-nightly-1.14.0.dev2019030115\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHGv-O7rvlYr",
        "colab_type": "text"
      },
      "source": [
        "Step 1: Import Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNRJhZHKvow2",
        "colab_type": "code",
        "outputId": "11e2d5fe-0cfa-4b46-b821-d57ed31771e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# You will need to mount your drive using the following commands:\n",
        "# For more information regarding mounting, please check this out: https://stackoverflow.com/questions/46986398/import-data-into-google-colaboratory\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kfo9s0OLyUbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You have to include the full link to the csv file containing your dataset\n",
        "Temperature_df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Celsius-to-Fahrenheit.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuegD3QCyyJF",
        "colab_type": "code",
        "outputId": "794048cf-e64e-4674-f9f9-fa4b077ce848",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "Temperature_df.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Celsius</th>\n",
              "      <th>Fahrenheit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-50</td>\n",
              "      <td>-58.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-40</td>\n",
              "      <td>-40.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-30</td>\n",
              "      <td>-22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-20</td>\n",
              "      <td>-4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-10</td>\n",
              "      <td>14.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Celsius  Fahrenheit\n",
              "0      -50       -58.0\n",
              "1      -40       -40.0\n",
              "2      -30       -22.0\n",
              "3      -20        -4.0\n",
              "4      -10        14.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LchLNFxby7X8",
        "colab_type": "code",
        "outputId": "5fc595b5-bd01-4283-8073-665e14f9beb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "Temperature_df.reset_index(drop=True, inplace=True)\n",
        "Temperature_df.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Celsius</th>\n",
              "      <th>Fahrenheit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-50</td>\n",
              "      <td>-58.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-40</td>\n",
              "      <td>-40.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-30</td>\n",
              "      <td>-22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-20</td>\n",
              "      <td>-4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-10</td>\n",
              "      <td>14.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Celsius  Fahrenheit\n",
              "0      -50       -58.0\n",
              "1      -40       -40.0\n",
              "2      -30       -22.0\n",
              "3      -20        -4.0\n",
              "4      -10        14.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7-mvUKezFHg",
        "colab_type": "code",
        "outputId": "94bfd59e-95fe-4f52-ba79-1fe5f035e466",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "Temperature_df.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 30 entries, 0 to 29\n",
            "Data columns (total 2 columns):\n",
            "Celsius       30 non-null int64\n",
            "Fahrenheit    30 non-null float64\n",
            "dtypes: float64(1), int64(1)\n",
            "memory usage: 608.0 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozH-7VI_zHfO",
        "colab_type": "code",
        "outputId": "b4433173-b999-4304-cac9-4d90879d48c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "Temperature_df.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Celsius</th>\n",
              "      <th>Fahrenheit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>30.000000</td>\n",
              "      <td>30.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>35.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>22.780815</td>\n",
              "      <td>41.005466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-50.000000</td>\n",
              "      <td>-58.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-6.750000</td>\n",
              "      <td>19.850000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>32.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.750000</td>\n",
              "      <td>45.950000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>60.000000</td>\n",
              "      <td>140.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Celsius  Fahrenheit\n",
              "count  30.000000   30.000000\n",
              "mean    2.000000   35.600000\n",
              "std    22.780815   41.005466\n",
              "min   -50.000000  -58.000000\n",
              "25%    -6.750000   19.850000\n",
              "50%     0.500000   32.900000\n",
              "75%     7.750000   45.950000\n",
              "max    60.000000  140.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FbFHnRyHpjA",
        "colab_type": "text"
      },
      "source": [
        "Step 2: Visualize the Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J66IgupZHtlF",
        "colab_type": "code",
        "outputId": "19eb13d1-d833-49ae-d633-851de5f25ba9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "sns.scatterplot(Temperature_df['Celsius'], Temperature_df['Fahrenheit'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f36437a30f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEGCAYAAACO8lkDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnBzMzCzFycHMzFKcHMzMLMXJwczMUv4ffIyNt4IiK8UAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qdGkkkFPhI3",
        "colab_type": "text"
      },
      "source": [
        "Step 3: Create Testing and Training Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDxh5F5wPmXL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = Temperature_df['Celsius']\n",
        "Y_train = Temperature_df['Fahrenheit']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmIst6cmQFI7",
        "colab_type": "text"
      },
      "source": [
        "Step 4: Build and Train the Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo0guHUZQNik",
        "colab_type": "code",
        "outputId": "e6ca03fc-2d0d-40a1-9cbb-2981a41523b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zC9-5hEZQR7l",
        "colab_type": "code",
        "outputId": "e4ccc994-a592-41be-884c-de0ae1e28712",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Y_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWQaTJEVRYcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "# units is the number of neurons \n",
        "model.add(tf.keras.layers.Dense(units=1, input_shape=[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWsFgmj9VnCS",
        "colab_type": "code",
        "outputId": "23f8b263-e6c4-4fdf-ca7d-14b19ddcacdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 1)                 2         \n",
            "=================================================================\n",
            "Total params: 2\n",
            "Trainable params: 2\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4BrmKkaW4nK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(1), loss='mean_squared_error')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKbCndNudGpY",
        "colab_type": "code",
        "outputId": "de033d8e-5d08-4c8f-a04a-a15360ca2e0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs_hist = model.fit(X_train, Y_train, epochs = 500)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "30/30 [==============================] - 1s 44ms/sample - loss: 2382.1121\n",
            "Epoch 2/500\n",
            "30/30 [==============================] - 0s 184us/sample - loss: 1160.3438\n",
            "Epoch 3/500\n",
            "30/30 [==============================] - 0s 110us/sample - loss: 926.8989\n",
            "Epoch 4/500\n",
            "30/30 [==============================] - 0s 116us/sample - loss: 1203.6981\n",
            "Epoch 5/500\n",
            "30/30 [==============================] - 0s 109us/sample - loss: 1329.5717\n",
            "Epoch 6/500\n",
            "30/30 [==============================] - 0s 136us/sample - loss: 1163.8555\n",
            "Epoch 7/500\n",
            "30/30 [==============================] - 0s 130us/sample - loss: 882.3962\n",
            "Epoch 8/500\n",
            "30/30 [==============================] - 0s 168us/sample - loss: 661.6572\n",
            "Epoch 9/500\n",
            "30/30 [==============================] - 0s 161us/sample - loss: 584.9442\n",
            "Epoch 10/500\n",
            "30/30 [==============================] - 0s 94us/sample - loss: 625.7601\n",
            "Epoch 11/500\n",
            "30/30 [==============================] - 0s 84us/sample - loss: 686.1569\n",
            "Epoch 12/500\n",
            "30/30 [==============================] - 0s 172us/sample - loss: 681.0402\n",
            "Epoch 13/500\n",
            "30/30 [==============================] - 0s 254us/sample - loss: 594.4366\n",
            "Epoch 14/500\n",
            "30/30 [==============================] - 0s 91us/sample - loss: 468.0870\n",
            "Epoch 15/500\n",
            "30/30 [==============================] - 0s 136us/sample - loss: 359.3905\n",
            "Epoch 16/500\n",
            "30/30 [==============================] - 0s 118us/sample - loss: 305.2419\n",
            "Epoch 17/500\n",
            "30/30 [==============================] - 0s 89us/sample - loss: 304.5531\n",
            "Epoch 18/500\n",
            "30/30 [==============================] - 0s 98us/sample - loss: 324.4966\n",
            "Epoch 19/500\n",
            "30/30 [==============================] - 0s 88us/sample - loss: 326.4756\n",
            "Epoch 20/500\n",
            "30/30 [==============================] - 0s 99us/sample - loss: 292.4004\n",
            "Epoch 21/500\n",
            "30/30 [==============================] - 0s 95us/sample - loss: 232.0821\n",
            "Epoch 22/500\n",
            "30/30 [==============================] - 0s 180us/sample - loss: 171.2943\n",
            "Epoch 23/500\n",
            "30/30 [==============================] - 0s 100us/sample - loss: 132.9460\n",
            "Epoch 24/500\n",
            "30/30 [==============================] - 0s 127us/sample - loss: 123.3521\n",
            "Epoch 25/500\n",
            "30/30 [==============================] - 0s 116us/sample - loss: 130.5213\n",
            "Epoch 26/500\n",
            "30/30 [==============================] - 0s 155us/sample - loss: 134.5593\n",
            "Epoch 27/500\n",
            "30/30 [==============================] - 0s 186us/sample - loss: 122.1657\n",
            "Epoch 28/500\n",
            "30/30 [==============================] - 0s 169us/sample - loss: 94.4323\n",
            "Epoch 29/500\n",
            "30/30 [==============================] - 0s 146us/sample - loss: 63.5858\n",
            "Epoch 30/500\n",
            "30/30 [==============================] - 0s 139us/sample - loss: 42.9269\n",
            "Epoch 31/500\n",
            "30/30 [==============================] - 0s 136us/sample - loss: 37.6566\n",
            "Epoch 32/500\n",
            "30/30 [==============================] - 0s 142us/sample - loss: 42.4156\n",
            "Epoch 33/500\n",
            "30/30 [==============================] - 0s 164us/sample - loss: 46.4758\n",
            "Epoch 34/500\n",
            "30/30 [==============================] - 0s 152us/sample - loss: 42.0965\n",
            "Epoch 35/500\n",
            "30/30 [==============================] - 0s 115us/sample - loss: 29.5350\n",
            "Epoch 36/500\n",
            "30/30 [==============================] - 0s 111us/sample - loss: 15.5228\n",
            "Epoch 37/500\n",
            "30/30 [==============================] - 0s 111us/sample - loss: 7.3321\n",
            "Epoch 38/500\n",
            "30/30 [==============================] - 0s 78us/sample - loss: 7.3362\n",
            "Epoch 39/500\n",
            "30/30 [==============================] - 0s 127us/sample - loss: 11.9192\n",
            "Epoch 40/500\n",
            "30/30 [==============================] - 0s 183us/sample - loss: 15.0154\n",
            "Epoch 41/500\n",
            "30/30 [==============================] - 0s 195us/sample - loss: 13.0328\n",
            "Epoch 42/500\n",
            "30/30 [==============================] - 0s 196us/sample - loss: 7.1678\n",
            "Epoch 43/500\n",
            "30/30 [==============================] - 0s 220us/sample - loss: 1.6874\n",
            "Epoch 44/500\n",
            "30/30 [==============================] - 0s 255us/sample - loss: 0.0977\n",
            "Epoch 45/500\n",
            "30/30 [==============================] - 0s 224us/sample - loss: 2.4716\n",
            "Epoch 46/500\n",
            "30/30 [==============================] - 0s 213us/sample - loss: 5.8748\n",
            "Epoch 47/500\n",
            "30/30 [==============================] - 0s 171us/sample - loss: 7.1477\n",
            "Epoch 48/500\n",
            "30/30 [==============================] - 0s 180us/sample - loss: 5.4710\n",
            "Epoch 49/500\n",
            "30/30 [==============================] - 0s 156us/sample - loss: 2.6419\n",
            "Epoch 50/500\n",
            "30/30 [==============================] - 0s 159us/sample - loss: 1.1630\n",
            "Epoch 51/500\n",
            "30/30 [==============================] - 0s 145us/sample - loss: 2.0371\n",
            "Epoch 52/500\n",
            "30/30 [==============================] - 0s 89us/sample - loss: 4.1455\n",
            "Epoch 53/500\n",
            "30/30 [==============================] - 0s 102us/sample - loss: 5.5127\n",
            "Epoch 54/500\n",
            "30/30 [==============================] - 0s 99us/sample - loss: 5.1179\n",
            "Epoch 55/500\n",
            "30/30 [==============================] - 0s 112us/sample - loss: 3.6150\n",
            "Epoch 56/500\n",
            "30/30 [==============================] - 0s 129us/sample - loss: 2.4936\n",
            "Epoch 57/500\n",
            "30/30 [==============================] - 0s 170us/sample - loss: 2.6410\n",
            "Epoch 58/500\n",
            "30/30 [==============================] - 0s 154us/sample - loss: 3.6544\n",
            "Epoch 59/500\n",
            "30/30 [==============================] - 0s 161us/sample - loss: 4.4041\n",
            "Epoch 60/500\n",
            "30/30 [==============================] - 0s 140us/sample - loss: 4.1631\n",
            "Epoch 61/500\n",
            "30/30 [==============================] - 0s 119us/sample - loss: 3.2008\n",
            "Epoch 62/500\n",
            "30/30 [==============================] - 0s 122us/sample - loss: 2.3796\n",
            "Epoch 63/500\n",
            "30/30 [==============================] - 0s 129us/sample - loss: 2.2716\n",
            "Epoch 64/500\n",
            "30/30 [==============================] - 0s 140us/sample - loss: 2.6807\n",
            "Epoch 65/500\n",
            "30/30 [==============================] - 0s 126us/sample - loss: 2.9529\n",
            "Epoch 66/500\n",
            "30/30 [==============================] - 0s 332us/sample - loss: 2.6672\n",
            "Epoch 67/500\n",
            "30/30 [==============================] - 0s 116us/sample - loss: 1.9984\n",
            "Epoch 68/500\n",
            "30/30 [==============================] - 0s 222us/sample - loss: 1.4568\n",
            "Epoch 69/500\n",
            "30/30 [==============================] - 0s 171us/sample - loss: 1.3473\n",
            "Epoch 70/500\n",
            "30/30 [==============================] - 0s 153us/sample - loss: 1.5122\n",
            "Epoch 71/500\n",
            "30/30 [==============================] - 0s 184us/sample - loss: 1.5622\n",
            "Epoch 72/500\n",
            "30/30 [==============================] - 0s 186us/sample - loss: 1.2967\n",
            "Epoch 73/500\n",
            "30/30 [==============================] - 0s 173us/sample - loss: 0.8717\n",
            "Epoch 74/500\n",
            "30/30 [==============================] - 0s 174us/sample - loss: 0.5870\n",
            "Epoch 75/500\n",
            "30/30 [==============================] - 0s 178us/sample - loss: 0.5646\n",
            "Epoch 76/500\n",
            "30/30 [==============================] - 0s 165us/sample - loss: 0.6558\n",
            "Epoch 77/500\n",
            "30/30 [==============================] - 0s 159us/sample - loss: 0.6369\n",
            "Epoch 78/500\n",
            "30/30 [==============================] - 0s 171us/sample - loss: 0.4480\n",
            "Epoch 79/500\n",
            "30/30 [==============================] - 0s 175us/sample - loss: 0.2267\n",
            "Epoch 80/500\n",
            "30/30 [==============================] - 0s 180us/sample - loss: 0.1326\n",
            "Epoch 81/500\n",
            "30/30 [==============================] - 0s 179us/sample - loss: 0.1781\n",
            "Epoch 82/500\n",
            "30/30 [==============================] - 0s 163us/sample - loss: 0.2388\n",
            "Epoch 83/500\n",
            "30/30 [==============================] - 0s 174us/sample - loss: 0.2059\n",
            "Epoch 84/500\n",
            "30/30 [==============================] - 0s 170us/sample - loss: 0.0968\n",
            "Epoch 85/500\n",
            "30/30 [==============================] - 0s 208us/sample - loss: 0.0143\n",
            "Epoch 86/500\n",
            "30/30 [==============================] - 0s 194us/sample - loss: 0.0216\n",
            "Epoch 87/500\n",
            "30/30 [==============================] - 0s 136us/sample - loss: 0.0804\n",
            "Epoch 88/500\n",
            "30/30 [==============================] - 0s 162us/sample - loss: 0.1082\n",
            "Epoch 89/500\n",
            "30/30 [==============================] - 0s 180us/sample - loss: 0.0742\n",
            "Epoch 90/500\n",
            "30/30 [==============================] - 0s 178us/sample - loss: 0.0230\n",
            "Epoch 91/500\n",
            "30/30 [==============================] - 0s 174us/sample - loss: 0.0125\n",
            "Epoch 92/500\n",
            "30/30 [==============================] - 0s 169us/sample - loss: 0.0471\n",
            "Epoch 93/500\n",
            "30/30 [==============================] - 0s 157us/sample - loss: 0.0814\n",
            "Epoch 94/500\n",
            "30/30 [==============================] - 0s 154us/sample - loss: 0.0788\n",
            "Epoch 95/500\n",
            "30/30 [==============================] - 0s 145us/sample - loss: 0.0503\n",
            "Epoch 96/500\n",
            "30/30 [==============================] - 0s 177us/sample - loss: 0.0339\n",
            "Epoch 97/500\n",
            "30/30 [==============================] - 0s 140us/sample - loss: 0.0467\n",
            "Epoch 98/500\n",
            "30/30 [==============================] - 0s 174us/sample - loss: 0.0692\n",
            "Epoch 99/500\n",
            "30/30 [==============================] - 0s 145us/sample - loss: 0.0736\n",
            "Epoch 100/500\n",
            "30/30 [==============================] - 0s 120us/sample - loss: 0.0569\n",
            "Epoch 101/500\n",
            "30/30 [==============================] - 0s 85us/sample - loss: 0.0405\n",
            "Epoch 102/500\n",
            "30/30 [==============================] - 0s 87us/sample - loss: 0.0407\n",
            "Epoch 103/500\n",
            "30/30 [==============================] - 0s 72us/sample - loss: 0.0514\n",
            "Epoch 104/500\n",
            "30/30 [==============================] - 0s 96us/sample - loss: 0.0546\n",
            "Epoch 105/500\n",
            "30/30 [==============================] - 0s 104us/sample - loss: 0.0441\n",
            "Epoch 106/500\n",
            "30/30 [==============================] - 0s 111us/sample - loss: 0.0305\n",
            "Epoch 107/500\n",
            "30/30 [==============================] - 0s 82us/sample - loss: 0.0262\n",
            "Epoch 108/500\n",
            "30/30 [==============================] - 0s 97us/sample - loss: 0.0302\n",
            "Epoch 109/500\n",
            "30/30 [==============================] - 0s 149us/sample - loss: 0.0319\n",
            "Epoch 110/500\n",
            "30/30 [==============================] - 0s 147us/sample - loss: 0.0254\n",
            "Epoch 111/500\n",
            "30/30 [==============================] - 0s 179us/sample - loss: 0.0160\n",
            "Epoch 112/500\n",
            "30/30 [==============================] - 0s 139us/sample - loss: 0.0118\n",
            "Epoch 113/500\n",
            "30/30 [==============================] - 0s 345us/sample - loss: 0.0134\n",
            "Epoch 114/500\n",
            "30/30 [==============================] - 0s 145us/sample - loss: 0.0146\n",
            "Epoch 115/500\n",
            "30/30 [==============================] - 0s 94us/sample - loss: 0.0112\n",
            "Epoch 116/500\n",
            "30/30 [==============================] - 0s 109us/sample - loss: 0.0057\n",
            "Epoch 117/500\n",
            "30/30 [==============================] - 0s 153us/sample - loss: 0.0031\n",
            "Epoch 118/500\n",
            "30/30 [==============================] - 0s 131us/sample - loss: 0.0043\n",
            "Epoch 119/500\n",
            "30/30 [==============================] - 0s 119us/sample - loss: 0.0056\n",
            "Epoch 120/500\n",
            "30/30 [==============================] - 0s 143us/sample - loss: 0.0041\n",
            "Epoch 121/500\n",
            "30/30 [==============================] - 0s 184us/sample - loss: 0.0013\n",
            "Epoch 122/500\n",
            "30/30 [==============================] - 0s 156us/sample - loss: 1.8508e-04\n",
            "Epoch 123/500\n",
            "30/30 [==============================] - 0s 153us/sample - loss: 0.0014\n",
            "Epoch 124/500\n",
            "30/30 [==============================] - 0s 138us/sample - loss: 0.0026\n",
            "Epoch 125/500\n",
            "30/30 [==============================] - 0s 173us/sample - loss: 0.0020\n",
            "Epoch 126/500\n",
            "30/30 [==============================] - 0s 180us/sample - loss: 6.3628e-04\n",
            "Epoch 127/500\n",
            "30/30 [==============================] - 0s 181us/sample - loss: 3.0346e-04\n",
            "Epoch 128/500\n",
            "30/30 [==============================] - 0s 145us/sample - loss: 0.0013\n",
            "Epoch 129/500\n",
            "30/30 [==============================] - 0s 126us/sample - loss: 0.0021\n",
            "Epoch 130/500\n",
            "30/30 [==============================] - 0s 134us/sample - loss: 0.0018\n",
            "Epoch 131/500\n",
            "30/30 [==============================] - 0s 126us/sample - loss: 0.0010\n",
            "Epoch 132/500\n",
            "30/30 [==============================] - 0s 125us/sample - loss: 9.4345e-04\n",
            "Epoch 133/500\n",
            "30/30 [==============================] - 0s 162us/sample - loss: 0.0016\n",
            "Epoch 134/500\n",
            "30/30 [==============================] - 0s 121us/sample - loss: 0.0020\n",
            "Epoch 135/500\n",
            "30/30 [==============================] - 0s 157us/sample - loss: 0.0016\n",
            "Epoch 136/500\n",
            "30/30 [==============================] - 0s 176us/sample - loss: 0.0011\n",
            "Epoch 137/500\n",
            "30/30 [==============================] - 0s 159us/sample - loss: 0.0011\n",
            "Epoch 138/500\n",
            "30/30 [==============================] - 0s 316us/sample - loss: 0.0014\n",
            "Epoch 139/500\n",
            "30/30 [==============================] - 0s 143us/sample - loss: 0.0015\n",
            "Epoch 140/500\n",
            "30/30 [==============================] - 0s 174us/sample - loss: 0.0011\n",
            "Epoch 141/500\n",
            "30/30 [==============================] - 0s 161us/sample - loss: 7.6984e-04\n",
            "Epoch 142/500\n",
            "30/30 [==============================] - 0s 135us/sample - loss: 7.3998e-04\n",
            "Epoch 143/500\n",
            "30/30 [==============================] - 0s 126us/sample - loss: 8.7884e-04\n",
            "Epoch 144/500\n",
            "30/30 [==============================] - 0s 150us/sample - loss: 8.2426e-04\n",
            "Epoch 145/500\n",
            "30/30 [==============================] - 0s 171us/sample - loss: 5.4861e-04\n",
            "Epoch 146/500\n",
            "30/30 [==============================] - 0s 169us/sample - loss: 3.4004e-04\n",
            "Epoch 147/500\n",
            "30/30 [==============================] - 0s 205us/sample - loss: 3.5179e-04\n",
            "Epoch 148/500\n",
            "30/30 [==============================] - 0s 173us/sample - loss: 4.1635e-04\n",
            "Epoch 149/500\n",
            "30/30 [==============================] - 0s 174us/sample - loss: 3.3561e-04\n",
            "Epoch 150/500\n",
            "30/30 [==============================] - 0s 174us/sample - loss: 1.6228e-04\n",
            "Epoch 151/500\n",
            "30/30 [==============================] - 0s 179us/sample - loss: 8.1373e-05\n",
            "Epoch 152/500\n",
            "30/30 [==============================] - 0s 86us/sample - loss: 1.2773e-04\n",
            "Epoch 153/500\n",
            "30/30 [==============================] - 0s 107us/sample - loss: 1.6306e-04\n",
            "Epoch 154/500\n",
            "30/30 [==============================] - 0s 96us/sample - loss: 1.0052e-04\n",
            "Epoch 155/500\n",
            "30/30 [==============================] - 0s 111us/sample - loss: 1.6771e-05\n",
            "Epoch 156/500\n",
            "30/30 [==============================] - 0s 74us/sample - loss: 1.3038e-05\n",
            "Epoch 157/500\n",
            "30/30 [==============================] - 0s 91us/sample - loss: 6.5518e-05\n",
            "Epoch 158/500\n",
            "30/30 [==============================] - 0s 481us/sample - loss: 8.0384e-05\n",
            "Epoch 159/500\n",
            "30/30 [==============================] - 0s 136us/sample - loss: 3.8985e-05\n",
            "Epoch 160/500\n",
            "30/30 [==============================] - 0s 129us/sample - loss: 1.0012e-05\n",
            "Epoch 161/500\n",
            "30/30 [==============================] - 0s 116us/sample - loss: 3.3978e-05\n",
            "Epoch 162/500\n",
            "30/30 [==============================] - 0s 123us/sample - loss: 6.9039e-05\n",
            "Epoch 163/500\n",
            "30/30 [==============================] - 0s 166us/sample - loss: 6.5388e-05\n",
            "Epoch 164/500\n",
            "30/30 [==============================] - 0s 170us/sample - loss: 3.8340e-05\n",
            "Epoch 165/500\n",
            "30/30 [==============================] - 0s 173us/sample - loss: 3.3894e-05\n",
            "Epoch 166/500\n",
            "30/30 [==============================] - 0s 170us/sample - loss: 5.5866e-05\n",
            "Epoch 167/500\n",
            "30/30 [==============================] - 0s 151us/sample - loss: 6.7595e-05\n",
            "Epoch 168/500\n",
            "30/30 [==============================] - 0s 171us/sample - loss: 5.3033e-05\n",
            "Epoch 169/500\n",
            "30/30 [==============================] - 0s 146us/sample - loss: 3.6513e-05\n",
            "Epoch 170/500\n",
            "30/30 [==============================] - 0s 189us/sample - loss: 3.9824e-05\n",
            "Epoch 171/500\n",
            "30/30 [==============================] - 0s 197us/sample - loss: 5.0473e-05\n",
            "Epoch 172/500\n",
            "30/30 [==============================] - 0s 247us/sample - loss: 4.6589e-05\n",
            "Epoch 173/500\n",
            "30/30 [==============================] - 0s 157us/sample - loss: 3.1384e-05\n",
            "Epoch 174/500\n",
            "30/30 [==============================] - 0s 204us/sample - loss: 2.3951e-05\n",
            "Epoch 175/500\n",
            "30/30 [==============================] - 0s 173us/sample - loss: 2.8172e-05\n",
            "Epoch 176/500\n",
            "30/30 [==============================] - 0s 234us/sample - loss: 2.9716e-05\n",
            "Epoch 177/500\n",
            "30/30 [==============================] - 0s 108us/sample - loss: 2.1086e-05\n",
            "Epoch 178/500\n",
            "30/30 [==============================] - 0s 188us/sample - loss: 1.1805e-05\n",
            "Epoch 179/500\n",
            "30/30 [==============================] - 0s 138us/sample - loss: 1.1061e-05\n",
            "Epoch 180/500\n",
            "30/30 [==============================] - 0s 169us/sample - loss: 1.3919e-05\n",
            "Epoch 181/500\n",
            "30/30 [==============================] - 0s 198us/sample - loss: 1.1410e-05\n",
            "Epoch 182/500\n",
            "30/30 [==============================] - 0s 97us/sample - loss: 4.9599e-06\n",
            "Epoch 183/500\n",
            "30/30 [==============================] - 0s 143us/sample - loss: 2.3221e-06\n",
            "Epoch 184/500\n",
            "30/30 [==============================] - 0s 131us/sample - loss: 4.5244e-06\n",
            "Epoch 185/500\n",
            "30/30 [==============================] - 0s 185us/sample - loss: 5.4991e-06\n",
            "Epoch 186/500\n",
            "30/30 [==============================] - 0s 187us/sample - loss: 2.6099e-06\n",
            "Epoch 187/500\n",
            "30/30 [==============================] - 0s 211us/sample - loss: 8.7925e-08\n",
            "Epoch 188/500\n",
            "30/30 [==============================] - 0s 166us/sample - loss: 1.1387e-06\n",
            "Epoch 189/500\n",
            "30/30 [==============================] - 0s 145us/sample - loss: 3.1056e-06\n",
            "Epoch 190/500\n",
            "30/30 [==============================] - 0s 174us/sample - loss: 2.6095e-06\n",
            "Epoch 191/500\n",
            "30/30 [==============================] - 0s 98us/sample - loss: 8.6422e-07\n",
            "Epoch 192/500\n",
            "30/30 [==============================] - 0s 86us/sample - loss: 9.2167e-07\n",
            "Epoch 193/500\n",
            "30/30 [==============================] - 0s 98us/sample - loss: 2.4960e-06\n",
            "Epoch 194/500\n",
            "30/30 [==============================] - 0s 131us/sample - loss: 2.9829e-06\n",
            "Epoch 195/500\n",
            "30/30 [==============================] - 0s 110us/sample - loss: 1.9695e-06\n",
            "Epoch 196/500\n",
            "30/30 [==============================] - 0s 120us/sample - loss: 1.4373e-06\n",
            "Epoch 197/500\n",
            "30/30 [==============================] - 0s 106us/sample - loss: 2.1967e-06\n",
            "Epoch 198/500\n",
            "30/30 [==============================] - 0s 85us/sample - loss: 2.8034e-06\n",
            "Epoch 199/500\n",
            "30/30 [==============================] - 0s 95us/sample - loss: 2.2614e-06\n",
            "Epoch 200/500\n",
            "30/30 [==============================] - 0s 94us/sample - loss: 1.5247e-06\n",
            "Epoch 201/500\n",
            "30/30 [==============================] - 0s 107us/sample - loss: 1.6454e-06\n",
            "Epoch 202/500\n",
            "30/30 [==============================] - 0s 104us/sample - loss: 2.0529e-06\n",
            "Epoch 203/500\n",
            "30/30 [==============================] - 0s 111us/sample - loss: 1.7997e-06\n",
            "Epoch 204/500\n",
            "30/30 [==============================] - 0s 101us/sample - loss: 1.1460e-06\n",
            "Epoch 205/500\n",
            "30/30 [==============================] - 0s 125us/sample - loss: 9.4249e-07\n",
            "Epoch 206/500\n",
            "30/30 [==============================] - 0s 75us/sample - loss: 1.1494e-06\n",
            "Epoch 207/500\n",
            "30/30 [==============================] - 0s 140us/sample - loss: 1.0765e-06\n",
            "Epoch 208/500\n",
            "30/30 [==============================] - 0s 169us/sample - loss: 6.3578e-07\n",
            "Epoch 209/500\n",
            "30/30 [==============================] - 0s 184us/sample - loss: 3.6833e-07\n",
            "Epoch 210/500\n",
            "30/30 [==============================] - 0s 152us/sample - loss: 4.6547e-07\n",
            "Epoch 211/500\n",
            "30/30 [==============================] - 0s 162us/sample - loss: 5.1379e-07\n",
            "Epoch 212/500\n",
            "30/30 [==============================] - 0s 355us/sample - loss: 2.8341e-07\n",
            "Epoch 213/500\n",
            "30/30 [==============================] - 0s 224us/sample - loss: 7.3533e-08\n",
            "Epoch 214/500\n",
            "30/30 [==============================] - 0s 224us/sample - loss: 1.2057e-07\n",
            "Epoch 215/500\n",
            "30/30 [==============================] - 0s 216us/sample - loss: 2.2348e-07\n",
            "Epoch 216/500\n",
            "30/30 [==============================] - 0s 164us/sample - loss: 1.4400e-07\n",
            "Epoch 217/500\n",
            "30/30 [==============================] - 0s 124us/sample - loss: 1.3526e-08\n",
            "Epoch 218/500\n",
            "30/30 [==============================] - 0s 200us/sample - loss: 3.5157e-08\n",
            "Epoch 219/500\n",
            "30/30 [==============================] - 0s 127us/sample - loss: 1.3591e-07\n",
            "Epoch 220/500\n",
            "30/30 [==============================] - 0s 178us/sample - loss: 1.3476e-07\n",
            "Epoch 221/500\n",
            "30/30 [==============================] - 0s 132us/sample - loss: 5.5934e-08\n",
            "Epoch 222/500\n",
            "30/30 [==============================] - 0s 328us/sample - loss: 5.5425e-08\n",
            "Epoch 223/500\n",
            "30/30 [==============================] - 0s 181us/sample - loss: 1.2756e-07\n",
            "Epoch 224/500\n",
            "30/30 [==============================] - 0s 155us/sample - loss: 1.4611e-07\n",
            "Epoch 225/500\n",
            "30/30 [==============================] - 0s 147us/sample - loss: 9.5551e-08\n",
            "Epoch 226/500\n",
            "30/30 [==============================] - 0s 173us/sample - loss: 7.7390e-08\n",
            "Epoch 227/500\n",
            "30/30 [==============================] - 0s 248us/sample - loss: 1.1664e-07\n",
            "Epoch 228/500\n",
            "30/30 [==============================] - 0s 147us/sample - loss: 1.3264e-07\n",
            "Epoch 229/500\n",
            "30/30 [==============================] - 0s 140us/sample - loss: 9.5005e-08\n",
            "Epoch 230/500\n",
            "30/30 [==============================] - 0s 154us/sample - loss: 6.8928e-08\n",
            "Epoch 231/500\n",
            "30/30 [==============================] - 0s 146us/sample - loss: 8.4107e-08\n",
            "Epoch 232/500\n",
            "30/30 [==============================] - 0s 139us/sample - loss: 9.2651e-08\n",
            "Epoch 233/500\n",
            "30/30 [==============================] - 0s 162us/sample - loss: 6.6138e-08\n",
            "Epoch 234/500\n",
            "30/30 [==============================] - 0s 133us/sample - loss: 4.0814e-08\n",
            "Epoch 235/500\n",
            "30/30 [==============================] - 0s 135us/sample - loss: 4.3701e-08\n",
            "Epoch 236/500\n",
            "30/30 [==============================] - 0s 153us/sample - loss: 5.0445e-08\n",
            "Epoch 237/500\n",
            "30/30 [==============================] - 0s 157us/sample - loss: 3.4643e-08\n",
            "Epoch 238/500\n",
            "30/30 [==============================] - 0s 149us/sample - loss: 1.5343e-08\n",
            "Epoch 239/500\n",
            "30/30 [==============================] - 0s 155us/sample - loss: 1.5932e-08\n",
            "Epoch 240/500\n",
            "30/30 [==============================] - 0s 133us/sample - loss: 2.1913e-08\n",
            "Epoch 241/500\n",
            "30/30 [==============================] - 0s 168us/sample - loss: 1.3983e-08\n",
            "Epoch 242/500\n",
            "30/30 [==============================] - 0s 212us/sample - loss: 2.7644e-09\n",
            "Epoch 243/500\n",
            "30/30 [==============================] - 0s 193us/sample - loss: 3.7898e-09\n",
            "Epoch 244/500\n",
            "30/30 [==============================] - 0s 176us/sample - loss: 9.9061e-09\n",
            "Epoch 245/500\n",
            "30/30 [==============================] - 0s 179us/sample - loss: 7.0362e-09\n",
            "Epoch 246/500\n",
            "30/30 [==============================] - 0s 195us/sample - loss: 8.0051e-10\n",
            "Epoch 247/500\n",
            "30/30 [==============================] - 0s 165us/sample - loss: 2.0306e-09\n",
            "Epoch 248/500\n",
            "30/30 [==============================] - 0s 182us/sample - loss: 7.1554e-09\n",
            "Epoch 249/500\n",
            "30/30 [==============================] - 0s 161us/sample - loss: 6.3472e-09\n",
            "Epoch 250/500\n",
            "30/30 [==============================] - 0s 162us/sample - loss: 3.1780e-09\n",
            "Epoch 251/500\n",
            "30/30 [==============================] - 0s 135us/sample - loss: 3.5073e-09\n",
            "Epoch 252/500\n",
            "30/30 [==============================] - 0s 168us/sample - loss: 6.9178e-09\n",
            "Epoch 253/500\n",
            "30/30 [==============================] - 0s 175us/sample - loss: 6.9834e-09\n",
            "Epoch 254/500\n",
            "30/30 [==============================] - 0s 173us/sample - loss: 4.3266e-09\n",
            "Epoch 255/500\n",
            "30/30 [==============================] - 0s 157us/sample - loss: 4.0339e-09\n",
            "Epoch 256/500\n",
            "30/30 [==============================] - 0s 159us/sample - loss: 6.2034e-09\n",
            "Epoch 257/500\n",
            "30/30 [==============================] - 0s 159us/sample - loss: 6.2034e-09\n",
            "Epoch 258/500\n",
            "30/30 [==============================] - 0s 172us/sample - loss: 3.6675e-09\n",
            "Epoch 259/500\n",
            "30/30 [==============================] - 0s 181us/sample - loss: 3.1495e-09\n",
            "Epoch 260/500\n",
            "30/30 [==============================] - 0s 173us/sample - loss: 4.3036e-09\n",
            "Epoch 261/500\n",
            "30/30 [==============================] - 0s 172us/sample - loss: 3.6159e-09\n",
            "Epoch 262/500\n",
            "30/30 [==============================] - 0s 162us/sample - loss: 2.0348e-09\n",
            "Epoch 263/500\n",
            "30/30 [==============================] - 0s 147us/sample - loss: 1.6535e-09\n",
            "Epoch 264/500\n",
            "30/30 [==============================] - 0s 150us/sample - loss: 2.4013e-09\n",
            "Epoch 265/500\n",
            "30/30 [==============================] - 0s 140us/sample - loss: 1.9348e-09\n",
            "Epoch 266/500\n",
            "30/30 [==============================] - 0s 154us/sample - loss: 8.2415e-10\n",
            "Epoch 267/500\n",
            "30/30 [==============================] - 0s 154us/sample - loss: 6.5814e-10\n",
            "Epoch 268/500\n",
            "30/30 [==============================] - 0s 162us/sample - loss: 1.1739e-09\n",
            "Epoch 269/500\n",
            "30/30 [==============================] - 0s 146us/sample - loss: 9.0892e-10\n",
            "Epoch 270/500\n",
            "30/30 [==============================] - 0s 157us/sample - loss: 2.4450e-10\n",
            "Epoch 271/500\n",
            "30/30 [==============================] - 0s 150us/sample - loss: 1.4870e-10\n",
            "Epoch 272/500\n",
            "30/30 [==============================] - 0s 165us/sample - loss: 5.5579e-10\n",
            "Epoch 273/500\n",
            "30/30 [==============================] - 0s 136us/sample - loss: 5.1771e-10\n",
            "Epoch 274/500\n",
            "30/30 [==============================] - 0s 141us/sample - loss: 8.8797e-11\n",
            "Epoch 275/500\n",
            "30/30 [==============================] - 0s 162us/sample - loss: 8.8433e-11\n",
            "Epoch 276/500\n",
            "30/30 [==============================] - 0s 150us/sample - loss: 4.0603e-10\n",
            "Epoch 277/500\n",
            "30/30 [==============================] - 0s 158us/sample - loss: 4.2713e-10\n",
            "Epoch 278/500\n",
            "30/30 [==============================] - 0s 123us/sample - loss: 2.0824e-10\n",
            "Epoch 279/500\n",
            "30/30 [==============================] - 0s 121us/sample - loss: 2.6172e-10\n",
            "Epoch 280/500\n",
            "30/30 [==============================] - 0s 145us/sample - loss: 4.3683e-10\n",
            "Epoch 281/500\n",
            "30/30 [==============================] - 0s 162us/sample - loss: 3.8675e-10\n",
            "Epoch 282/500\n",
            "30/30 [==============================] - 0s 147us/sample - loss: 1.9296e-10\n",
            "Epoch 283/500\n",
            "30/30 [==============================] - 0s 151us/sample - loss: 2.5772e-10\n",
            "Epoch 284/500\n",
            "30/30 [==============================] - 0s 145us/sample - loss: 3.4916e-10\n",
            "Epoch 285/500\n",
            "30/30 [==============================] - 0s 144us/sample - loss: 2.7627e-10\n",
            "Epoch 286/500\n",
            "30/30 [==============================] - 0s 150us/sample - loss: 1.9321e-10\n",
            "Epoch 287/500\n",
            "30/30 [==============================] - 0s 135us/sample - loss: 2.2255e-10\n",
            "Epoch 288/500\n",
            "30/30 [==============================] - 0s 156us/sample - loss: 3.2126e-10\n",
            "Epoch 289/500\n",
            "30/30 [==============================] - 0s 157us/sample - loss: 2.0376e-10\n",
            "Epoch 290/500\n",
            "30/30 [==============================] - 0s 140us/sample - loss: 8.5038e-11\n",
            "Epoch 291/500\n",
            "30/30 [==============================] - 0s 166us/sample - loss: 1.3136e-10\n",
            "Epoch 292/500\n",
            "30/30 [==============================] - 0s 170us/sample - loss: 8.8433e-11\n",
            "Epoch 293/500\n",
            "30/30 [==============================] - 0s 165us/sample - loss: 4.1018e-11\n",
            "Epoch 294/500\n",
            "30/30 [==============================] - 0s 166us/sample - loss: 5.0022e-12\n",
            "Epoch 295/500\n",
            "30/30 [==============================] - 0s 162us/sample - loss: 5.0841e-11\n",
            "Epoch 296/500\n",
            "30/30 [==============================] - 0s 180us/sample - loss: 5.0841e-11\n",
            "Epoch 297/500\n",
            "30/30 [==============================] - 0s 165us/sample - loss: 2.1494e-11\n",
            "Epoch 298/500\n",
            "30/30 [==============================] - 0s 164us/sample - loss: 6.3665e-13\n",
            "Epoch 299/500\n",
            "30/30 [==============================] - 0s 170us/sample - loss: 5.0356e-11\n",
            "Epoch 300/500\n",
            "30/30 [==============================] - 0s 146us/sample - loss: 5.0356e-11\n",
            "Epoch 301/500\n",
            "30/30 [==============================] - 0s 184us/sample - loss: 1.0217e-11\n",
            "Epoch 302/500\n",
            "30/30 [==============================] - 0s 115us/sample - loss: 6.3665e-13\n",
            "Epoch 303/500\n",
            "30/30 [==============================] - 0s 113us/sample - loss: 5.0841e-11\n",
            "Epoch 304/500\n",
            "30/30 [==============================] - 0s 194us/sample - loss: 5.0841e-11\n",
            "Epoch 305/500\n",
            "30/30 [==============================] - 0s 196us/sample - loss: 6.3665e-13\n",
            "Epoch 306/500\n",
            "30/30 [==============================] - 0s 183us/sample - loss: 1.0217e-11\n",
            "Epoch 307/500\n",
            "30/30 [==============================] - 0s 204us/sample - loss: 5.0356e-11\n",
            "Epoch 308/500\n",
            "30/30 [==============================] - 0s 186us/sample - loss: 1.0217e-11\n",
            "Epoch 309/500\n",
            "30/30 [==============================] - 0s 161us/sample - loss: 6.3665e-13\n",
            "Epoch 310/500\n",
            "30/30 [==============================] - 0s 128us/sample - loss: 6.3665e-13\n",
            "Epoch 311/500\n",
            "30/30 [==============================] - 0s 143us/sample - loss: 2.1494e-11\n",
            "Epoch 312/500\n",
            "30/30 [==============================] - 0s 124us/sample - loss: 2.1494e-11\n",
            "Epoch 313/500\n",
            "30/30 [==============================] - 0s 156us/sample - loss: 6.3665e-13\n",
            "Epoch 314/500\n",
            "30/30 [==============================] - 0s 131us/sample - loss: 6.3665e-13\n",
            "Epoch 315/500\n",
            "30/30 [==============================] - 0s 132us/sample - loss: 1.0217e-11\n",
            "Epoch 316/500\n",
            "30/30 [==============================] - 0s 198us/sample - loss: 1.0217e-11\n",
            "Epoch 317/500\n",
            "30/30 [==============================] - 0s 183us/sample - loss: 1.0217e-11\n",
            "Epoch 318/500\n",
            "30/30 [==============================] - 0s 205us/sample - loss: 6.3665e-13\n",
            "Epoch 319/500\n",
            "30/30 [==============================] - 0s 233us/sample - loss: 6.3665e-13\n",
            "Epoch 320/500\n",
            "30/30 [==============================] - 0s 211us/sample - loss: 2.1494e-11\n",
            "Epoch 321/500\n",
            "30/30 [==============================] - 0s 231us/sample - loss: 2.1494e-11\n",
            "Epoch 322/500\n",
            "30/30 [==============================] - 0s 195us/sample - loss: 6.3665e-13\n",
            "Epoch 323/500\n",
            "30/30 [==============================] - 0s 206us/sample - loss: 6.3665e-13\n",
            "Epoch 324/500\n",
            "30/30 [==============================] - 0s 195us/sample - loss: 1.0217e-11\n",
            "Epoch 325/500\n",
            "30/30 [==============================] - 0s 189us/sample - loss: 1.0217e-11\n",
            "Epoch 326/500\n",
            "30/30 [==============================] - 0s 179us/sample - loss: 1.0217e-11\n",
            "Epoch 327/500\n",
            "30/30 [==============================] - 0s 203us/sample - loss: 6.3665e-13\n",
            "Epoch 328/500\n",
            "30/30 [==============================] - 0s 255us/sample - loss: 6.3665e-13\n",
            "Epoch 329/500\n",
            "30/30 [==============================] - 0s 203us/sample - loss: 2.1494e-11\n",
            "Epoch 330/500\n",
            "30/30 [==============================] - 0s 211us/sample - loss: 2.1494e-11\n",
            "Epoch 331/500\n",
            "30/30 [==============================] - 0s 203us/sample - loss: 6.3665e-13\n",
            "Epoch 332/500\n",
            "30/30 [==============================] - 0s 220us/sample - loss: 6.3665e-13\n",
            "Epoch 333/500\n",
            "30/30 [==============================] - 0s 197us/sample - loss: 1.0217e-11\n",
            "Epoch 334/500\n",
            "30/30 [==============================] - 0s 148us/sample - loss: 5.0356e-11\n",
            "Epoch 335/500\n",
            "30/30 [==============================] - 0s 135us/sample - loss: 1.0217e-11\n",
            "Epoch 336/500\n",
            "30/30 [==============================] - 0s 144us/sample - loss: 6.3665e-13\n",
            "Epoch 337/500\n",
            "30/30 [==============================] - 0s 84us/sample - loss: 2.1494e-11\n",
            "Epoch 338/500\n",
            "30/30 [==============================] - 0s 132us/sample - loss: 2.1494e-11\n",
            "Epoch 339/500\n",
            "30/30 [==============================] - 0s 161us/sample - loss: 6.3665e-13\n",
            "Epoch 340/500\n",
            "30/30 [==============================] - 0s 213us/sample - loss: 6.3665e-13\n",
            "Epoch 341/500\n",
            "30/30 [==============================] - 0s 185us/sample - loss: 1.0217e-11\n",
            "Epoch 342/500\n",
            "30/30 [==============================] - 0s 104us/sample - loss: 1.0217e-11\n",
            "Epoch 343/500\n",
            "30/30 [==============================] - 0s 160us/sample - loss: 6.3665e-13\n",
            "Epoch 344/500\n",
            "30/30 [==============================] - 0s 355us/sample - loss: 6.3665e-13\n",
            "Epoch 345/500\n",
            "30/30 [==============================] - 0s 301us/sample - loss: 6.3665e-13\n",
            "Epoch 346/500\n",
            "30/30 [==============================] - 0s 259us/sample - loss: 6.3665e-13\n",
            "Epoch 347/500\n",
            "30/30 [==============================] - 0s 185us/sample - loss: 6.3665e-13\n",
            "Epoch 348/500\n",
            "30/30 [==============================] - 0s 148us/sample - loss: 6.3665e-13\n",
            "Epoch 349/500\n",
            "30/30 [==============================] - 0s 198us/sample - loss: 6.3665e-13\n",
            "Epoch 350/500\n",
            "30/30 [==============================] - 0s 81us/sample - loss: 6.3665e-13\n",
            "Epoch 351/500\n",
            "30/30 [==============================] - 0s 144us/sample - loss: 6.3665e-13\n",
            "Epoch 352/500\n",
            "30/30 [==============================] - 0s 230us/sample - loss: 6.3665e-13\n",
            "Epoch 353/500\n",
            "30/30 [==============================] - 0s 261us/sample - loss: 6.3665e-13\n",
            "Epoch 354/500\n",
            "30/30 [==============================] - 0s 186us/sample - loss: 6.3665e-13\n",
            "Epoch 355/500\n",
            "30/30 [==============================] - 0s 160us/sample - loss: 6.3665e-13\n",
            "Epoch 356/500\n",
            "30/30 [==============================] - 0s 148us/sample - loss: 6.3665e-13\n",
            "Epoch 357/500\n",
            "30/30 [==============================] - 0s 149us/sample - loss: 6.3665e-13\n",
            "Epoch 358/500\n",
            "30/30 [==============================] - 0s 177us/sample - loss: 6.3665e-13\n",
            "Epoch 359/500\n",
            "30/30 [==============================] - 0s 158us/sample - loss: 6.3665e-13\n",
            "Epoch 360/500\n",
            "30/30 [==============================] - 0s 141us/sample - loss: 6.3665e-13\n",
            "Epoch 361/500\n",
            "30/30 [==============================] - 0s 96us/sample - loss: 6.3665e-13\n",
            "Epoch 362/500\n",
            "30/30 [==============================] - 0s 152us/sample - loss: 6.3665e-13\n",
            "Epoch 363/500\n",
            "30/30 [==============================] - 0s 150us/sample - loss: 6.3665e-13\n",
            "Epoch 364/500\n",
            "30/30 [==============================] - 0s 137us/sample - loss: 6.3665e-13\n",
            "Epoch 365/500\n",
            "30/30 [==============================] - 0s 133us/sample - loss: 6.3665e-13\n",
            "Epoch 366/500\n",
            "30/30 [==============================] - 0s 141us/sample - loss: 6.3665e-13\n",
            "Epoch 367/500\n",
            "30/30 [==============================] - 0s 139us/sample - loss: 6.3665e-13\n",
            "Epoch 368/500\n",
            "30/30 [==============================] - 0s 135us/sample - loss: 6.3665e-13\n",
            "Epoch 369/500\n",
            "30/30 [==============================] - 0s 145us/sample - loss: 6.3665e-13\n",
            "Epoch 370/500\n",
            "30/30 [==============================] - 0s 153us/sample - loss: 6.3665e-13\n",
            "Epoch 371/500\n",
            "30/30 [==============================] - 0s 177us/sample - loss: 6.3665e-13\n",
            "Epoch 372/500\n",
            "30/30 [==============================] - 0s 150us/sample - loss: 6.3665e-13\n",
            "Epoch 373/500\n",
            "30/30 [==============================] - 0s 197us/sample - loss: 6.3665e-13\n",
            "Epoch 374/500\n",
            "30/30 [==============================] - 0s 175us/sample - loss: 6.3665e-13\n",
            "Epoch 375/500\n",
            "30/30 [==============================] - 0s 185us/sample - loss: 6.3665e-13\n",
            "Epoch 376/500\n",
            "30/30 [==============================] - 0s 186us/sample - loss: 6.3665e-13\n",
            "Epoch 377/500\n",
            "30/30 [==============================] - 0s 168us/sample - loss: 6.3665e-13\n",
            "Epoch 378/500\n",
            "30/30 [==============================] - 0s 148us/sample - loss: 6.3665e-13\n",
            "Epoch 379/500\n",
            "30/30 [==============================] - 0s 239us/sample - loss: 6.3665e-13\n",
            "Epoch 380/500\n",
            "30/30 [==============================] - 0s 181us/sample - loss: 6.3665e-13\n",
            "Epoch 381/500\n",
            "30/30 [==============================] - 0s 156us/sample - loss: 6.3665e-13\n",
            "Epoch 382/500\n",
            "30/30 [==============================] - 0s 156us/sample - loss: 6.3665e-13\n",
            "Epoch 383/500\n",
            "30/30 [==============================] - 0s 144us/sample - loss: 6.3665e-13\n",
            "Epoch 384/500\n",
            "30/30 [==============================] - 0s 173us/sample - loss: 6.3665e-13\n",
            "Epoch 385/500\n",
            "30/30 [==============================] - 0s 94us/sample - loss: 6.3665e-13\n",
            "Epoch 386/500\n",
            "30/30 [==============================] - 0s 78us/sample - loss: 6.3665e-13\n",
            "Epoch 387/500\n",
            "30/30 [==============================] - 0s 158us/sample - loss: 6.3665e-13\n",
            "Epoch 388/500\n",
            "30/30 [==============================] - 0s 125us/sample - loss: 6.3665e-13\n",
            "Epoch 389/500\n",
            "30/30 [==============================] - 0s 143us/sample - loss: 6.3665e-13\n",
            "Epoch 390/500\n",
            "30/30 [==============================] - 0s 109us/sample - loss: 6.3665e-13\n",
            "Epoch 391/500\n",
            "30/30 [==============================] - 0s 152us/sample - loss: 6.3665e-13\n",
            "Epoch 392/500\n",
            "30/30 [==============================] - 0s 217us/sample - loss: 6.3665e-13\n",
            "Epoch 393/500\n",
            "30/30 [==============================] - 0s 78us/sample - loss: 6.3665e-13\n",
            "Epoch 394/500\n",
            "30/30 [==============================] - 0s 117us/sample - loss: 6.3665e-13\n",
            "Epoch 395/500\n",
            "30/30 [==============================] - 0s 92us/sample - loss: 6.3665e-13\n",
            "Epoch 396/500\n",
            "30/30 [==============================] - 0s 140us/sample - loss: 6.3665e-13\n",
            "Epoch 397/500\n",
            "30/30 [==============================] - 0s 152us/sample - loss: 6.3665e-13\n",
            "Epoch 398/500\n",
            "30/30 [==============================] - 0s 154us/sample - loss: 6.3665e-13\n",
            "Epoch 399/500\n",
            "30/30 [==============================] - 0s 160us/sample - loss: 6.3665e-13\n",
            "Epoch 400/500\n",
            "30/30 [==============================] - 0s 201us/sample - loss: 6.3665e-13\n",
            "Epoch 401/500\n",
            "30/30 [==============================] - 0s 206us/sample - loss: 6.3665e-13\n",
            "Epoch 402/500\n",
            "30/30 [==============================] - 0s 182us/sample - loss: 6.3665e-13\n",
            "Epoch 403/500\n",
            "30/30 [==============================] - 0s 169us/sample - loss: 6.3665e-13\n",
            "Epoch 404/500\n",
            "30/30 [==============================] - 0s 169us/sample - loss: 6.3665e-13\n",
            "Epoch 405/500\n",
            "30/30 [==============================] - 0s 132us/sample - loss: 6.3665e-13\n",
            "Epoch 406/500\n",
            "30/30 [==============================] - 0s 260us/sample - loss: 6.3665e-13\n",
            "Epoch 407/500\n",
            "30/30 [==============================] - 0s 125us/sample - loss: 6.3665e-13\n",
            "Epoch 408/500\n",
            "30/30 [==============================] - 0s 161us/sample - loss: 6.3665e-13\n",
            "Epoch 409/500\n",
            "30/30 [==============================] - 0s 145us/sample - loss: 6.3665e-13\n",
            "Epoch 410/500\n",
            "30/30 [==============================] - 0s 122us/sample - loss: 6.3665e-13\n",
            "Epoch 411/500\n",
            "30/30 [==============================] - 0s 124us/sample - loss: 6.3665e-13\n",
            "Epoch 412/500\n",
            "30/30 [==============================] - 0s 140us/sample - loss: 6.3665e-13\n",
            "Epoch 413/500\n",
            "30/30 [==============================] - 0s 146us/sample - loss: 6.3665e-13\n",
            "Epoch 414/500\n",
            "30/30 [==============================] - 0s 129us/sample - loss: 6.3665e-13\n",
            "Epoch 415/500\n",
            "30/30 [==============================] - 0s 158us/sample - loss: 6.3665e-13\n",
            "Epoch 416/500\n",
            "30/30 [==============================] - 0s 148us/sample - loss: 6.3665e-13\n",
            "Epoch 417/500\n",
            "30/30 [==============================] - 0s 153us/sample - loss: 6.3665e-13\n",
            "Epoch 418/500\n",
            "30/30 [==============================] - 0s 137us/sample - loss: 6.3665e-13\n",
            "Epoch 419/500\n",
            "30/30 [==============================] - 0s 131us/sample - loss: 6.3665e-13\n",
            "Epoch 420/500\n",
            "30/30 [==============================] - 0s 128us/sample - loss: 6.3665e-13\n",
            "Epoch 421/500\n",
            "30/30 [==============================] - 0s 184us/sample - loss: 6.3665e-13\n",
            "Epoch 422/500\n",
            "30/30 [==============================] - 0s 162us/sample - loss: 6.3665e-13\n",
            "Epoch 423/500\n",
            "30/30 [==============================] - 0s 164us/sample - loss: 6.3665e-13\n",
            "Epoch 424/500\n",
            "30/30 [==============================] - 0s 139us/sample - loss: 6.3665e-13\n",
            "Epoch 425/500\n",
            "30/30 [==============================] - 0s 164us/sample - loss: 6.3665e-13\n",
            "Epoch 426/500\n",
            "30/30 [==============================] - 0s 152us/sample - loss: 6.3665e-13\n",
            "Epoch 427/500\n",
            "30/30 [==============================] - 0s 148us/sample - loss: 6.3665e-13\n",
            "Epoch 428/500\n",
            "30/30 [==============================] - 0s 153us/sample - loss: 6.3665e-13\n",
            "Epoch 429/500\n",
            "30/30 [==============================] - 0s 139us/sample - loss: 6.3665e-13\n",
            "Epoch 430/500\n",
            "30/30 [==============================] - 0s 144us/sample - loss: 6.3665e-13\n",
            "Epoch 431/500\n",
            "30/30 [==============================] - 0s 156us/sample - loss: 6.3665e-13\n",
            "Epoch 432/500\n",
            "30/30 [==============================] - 0s 141us/sample - loss: 6.3665e-13\n",
            "Epoch 433/500\n",
            "30/30 [==============================] - 0s 137us/sample - loss: 6.3665e-13\n",
            "Epoch 434/500\n",
            "30/30 [==============================] - 0s 153us/sample - loss: 6.3665e-13\n",
            "Epoch 435/500\n",
            "30/30 [==============================] - 0s 175us/sample - loss: 6.3665e-13\n",
            "Epoch 436/500\n",
            "30/30 [==============================] - 0s 138us/sample - loss: 6.3665e-13\n",
            "Epoch 437/500\n",
            "30/30 [==============================] - 0s 139us/sample - loss: 6.3665e-13\n",
            "Epoch 438/500\n",
            "30/30 [==============================] - 0s 140us/sample - loss: 6.3665e-13\n",
            "Epoch 439/500\n",
            "30/30 [==============================] - 0s 150us/sample - loss: 6.3665e-13\n",
            "Epoch 440/500\n",
            "30/30 [==============================] - 0s 145us/sample - loss: 6.3665e-13\n",
            "Epoch 441/500\n",
            "30/30 [==============================] - 0s 160us/sample - loss: 6.3665e-13\n",
            "Epoch 442/500\n",
            "30/30 [==============================] - 0s 151us/sample - loss: 6.3665e-13\n",
            "Epoch 443/500\n",
            "30/30 [==============================] - 0s 140us/sample - loss: 6.3665e-13\n",
            "Epoch 444/500\n",
            "30/30 [==============================] - 0s 151us/sample - loss: 6.3665e-13\n",
            "Epoch 445/500\n",
            "30/30 [==============================] - 0s 141us/sample - loss: 6.3665e-13\n",
            "Epoch 446/500\n",
            "30/30 [==============================] - 0s 154us/sample - loss: 6.3665e-13\n",
            "Epoch 447/500\n",
            "30/30 [==============================] - 0s 182us/sample - loss: 6.3665e-13\n",
            "Epoch 448/500\n",
            "30/30 [==============================] - 0s 195us/sample - loss: 6.3665e-13\n",
            "Epoch 449/500\n",
            "30/30 [==============================] - 0s 213us/sample - loss: 6.3665e-13\n",
            "Epoch 450/500\n",
            "30/30 [==============================] - 0s 117us/sample - loss: 6.3665e-13\n",
            "Epoch 451/500\n",
            "30/30 [==============================] - 0s 137us/sample - loss: 6.3665e-13\n",
            "Epoch 452/500\n",
            "30/30 [==============================] - 0s 139us/sample - loss: 6.3665e-13\n",
            "Epoch 453/500\n",
            "30/30 [==============================] - 0s 132us/sample - loss: 6.3665e-13\n",
            "Epoch 454/500\n",
            "30/30 [==============================] - 0s 149us/sample - loss: 6.3665e-13\n",
            "Epoch 455/500\n",
            "30/30 [==============================] - 0s 155us/sample - loss: 6.3665e-13\n",
            "Epoch 456/500\n",
            "30/30 [==============================] - 0s 155us/sample - loss: 6.3665e-13\n",
            "Epoch 457/500\n",
            "30/30 [==============================] - 0s 153us/sample - loss: 6.3665e-13\n",
            "Epoch 458/500\n",
            "30/30 [==============================] - 0s 150us/sample - loss: 6.3665e-13\n",
            "Epoch 459/500\n",
            "30/30 [==============================] - 0s 147us/sample - loss: 6.3665e-13\n",
            "Epoch 460/500\n",
            "30/30 [==============================] - 0s 145us/sample - loss: 6.3665e-13\n",
            "Epoch 461/500\n",
            "30/30 [==============================] - 0s 148us/sample - loss: 6.3665e-13\n",
            "Epoch 462/500\n",
            "30/30 [==============================] - 0s 149us/sample - loss: 6.3665e-13\n",
            "Epoch 463/500\n",
            "30/30 [==============================] - 0s 208us/sample - loss: 6.3665e-13\n",
            "Epoch 464/500\n",
            "30/30 [==============================] - 0s 186us/sample - loss: 6.3665e-13\n",
            "Epoch 465/500\n",
            "30/30 [==============================] - 0s 151us/sample - loss: 6.3665e-13\n",
            "Epoch 466/500\n",
            "30/30 [==============================] - 0s 161us/sample - loss: 6.3665e-13\n",
            "Epoch 467/500\n",
            "30/30 [==============================] - 0s 162us/sample - loss: 6.3665e-13\n",
            "Epoch 468/500\n",
            "30/30 [==============================] - 0s 167us/sample - loss: 6.3665e-13\n",
            "Epoch 469/500\n",
            "30/30 [==============================] - 0s 121us/sample - loss: 6.3665e-13\n",
            "Epoch 470/500\n",
            "30/30 [==============================] - 0s 126us/sample - loss: 6.3665e-13\n",
            "Epoch 471/500\n",
            "30/30 [==============================] - 0s 157us/sample - loss: 6.3665e-13\n",
            "Epoch 472/500\n",
            "30/30 [==============================] - 0s 129us/sample - loss: 6.3665e-13\n",
            "Epoch 473/500\n",
            "30/30 [==============================] - 0s 146us/sample - loss: 6.3665e-13\n",
            "Epoch 474/500\n",
            "30/30 [==============================] - 0s 134us/sample - loss: 6.3665e-13\n",
            "Epoch 475/500\n",
            "30/30 [==============================] - 0s 141us/sample - loss: 6.3665e-13\n",
            "Epoch 476/500\n",
            "30/30 [==============================] - 0s 139us/sample - loss: 6.3665e-13\n",
            "Epoch 477/500\n",
            "30/30 [==============================] - 0s 148us/sample - loss: 6.3665e-13\n",
            "Epoch 478/500\n",
            "30/30 [==============================] - 0s 144us/sample - loss: 6.3665e-13\n",
            "Epoch 479/500\n",
            "30/30 [==============================] - 0s 137us/sample - loss: 6.3665e-13\n",
            "Epoch 480/500\n",
            "30/30 [==============================] - 0s 139us/sample - loss: 6.3665e-13\n",
            "Epoch 481/500\n",
            "30/30 [==============================] - 0s 138us/sample - loss: 6.3665e-13\n",
            "Epoch 482/500\n",
            "30/30 [==============================] - 0s 127us/sample - loss: 6.3665e-13\n",
            "Epoch 483/500\n",
            "30/30 [==============================] - 0s 151us/sample - loss: 6.3665e-13\n",
            "Epoch 484/500\n",
            "30/30 [==============================] - 0s 152us/sample - loss: 6.3665e-13\n",
            "Epoch 485/500\n",
            "30/30 [==============================] - 0s 146us/sample - loss: 6.3665e-13\n",
            "Epoch 486/500\n",
            "30/30 [==============================] - 0s 148us/sample - loss: 6.3665e-13\n",
            "Epoch 487/500\n",
            "30/30 [==============================] - 0s 154us/sample - loss: 6.3665e-13\n",
            "Epoch 488/500\n",
            "30/30 [==============================] - 0s 136us/sample - loss: 6.3665e-13\n",
            "Epoch 489/500\n",
            "30/30 [==============================] - 0s 146us/sample - loss: 6.3665e-13\n",
            "Epoch 490/500\n",
            "30/30 [==============================] - 0s 175us/sample - loss: 6.3665e-13\n",
            "Epoch 491/500\n",
            "30/30 [==============================] - 0s 178us/sample - loss: 6.3665e-13\n",
            "Epoch 492/500\n",
            "30/30 [==============================] - 0s 175us/sample - loss: 6.3665e-13\n",
            "Epoch 493/500\n",
            "30/30 [==============================] - 0s 175us/sample - loss: 6.3665e-13\n",
            "Epoch 494/500\n",
            "30/30 [==============================] - 0s 192us/sample - loss: 6.3665e-13\n",
            "Epoch 495/500\n",
            "30/30 [==============================] - 0s 335us/sample - loss: 6.3665e-13\n",
            "Epoch 496/500\n",
            "30/30 [==============================] - 0s 150us/sample - loss: 6.3665e-13\n",
            "Epoch 497/500\n",
            "30/30 [==============================] - 0s 166us/sample - loss: 6.3665e-13\n",
            "Epoch 498/500\n",
            "30/30 [==============================] - 0s 190us/sample - loss: 6.3665e-13\n",
            "Epoch 499/500\n",
            "30/30 [==============================] - 0s 153us/sample - loss: 6.3665e-13\n",
            "Epoch 500/500\n",
            "30/30 [==============================] - 0s 160us/sample - loss: 6.3665e-13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4mNs3hvLE3a",
        "colab_type": "text"
      },
      "source": [
        "Step 5: Evaluate the Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-HtqdrMLMU9",
        "colab_type": "code",
        "outputId": "de507bca-733b-47e3-8b18-2b757f7502df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "epochs_hist.history.keys()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kc6vzyCYEXZy",
        "colab_type": "text"
      },
      "source": [
        "With epochs_hist.histor.keys(), we store the loss values associated with each epoch in a dictionary. Then we can use Matplotlib to visualize the loss. Here we used the basic Matplotlib functional style to create a plot instead of the object oriented method where we create a figure object and then call methods or attributes off of that object. With the graph, we can see that the error reaches a plateau after about 75 to 100 epochs. This means that we don’t need to use all of that computational power of doing 500 epochs. We can stop after 75 to 100 epochs. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aufwXnxmM-Vl",
        "colab_type": "code",
        "outputId": "70d5e97a-2d24-4519-c878-70031b79e2cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "plt.plot(epochs_hist.history['loss'])\n",
        "plt.title('Model Loss Progress During Training')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Training Loss')\n",
        "plt.legend('Traing Loss')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f71b43c2b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukSdzx-3Peck",
        "colab_type": "code",
        "outputId": "3302a02a-2b39-4ecd-c073-cded7a6f2ee7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.get_weights()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[1.8]], dtype=float32), array([32.], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJvJNIgLEqKb",
        "colab_type": "text"
      },
      "source": [
        "We use model.get_weights() to retrieve the weights. The model had a weight of 1.8 and a bias of 32. These numbers are the coefficients of our equation. 9/5 is 1.8. Using just input and output data, the model figured out the equation for converting Celsius temperatures to Fahrenheit. We perform a feed forward pass so the model uses the temperature in Celsius and comes up with a prediction. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3nL1i0ARWsD",
        "colab_type": "code",
        "outputId": "aa98b36a-0720-429b-ff21-2edf0d5b38e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Temp_C = 60\n",
        "Temp_F = model.predict([Temp_C])\n",
        "print('Temperature in DegF Using ANN=', Temp_F)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Temperature in DegF Using ANN= [[140.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mb5Y7u2-78L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc12e961-f141-41d5-e9a5-020e92e82594"
      },
      "source": [
        "# Let's confirm with the equation\n",
        "Temp_F = 9/5 * Temp_C + 32\n",
        "print('Temperature in DegF Using Equation=',Temp_F)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Temperature in DegF Using Equation= 140.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}